{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0035, -0.0035, -0.0035,  ..., -0.0035, -0.0035, -0.0035],\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#optimizers require the parameter to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0149,  0.0338,  0.0030,  ..., -0.0187,  0.0102,  0.0152],\n",
      "        [ 0.0268, -0.0235, -0.0029,  ..., -0.0066,  0.0177, -0.0256],\n",
      "        [-0.0166, -0.0094,  0.0173,  ...,  0.0128, -0.0040, -0.0309],\n",
      "        ...,\n",
      "        [-0.0334, -0.0029, -0.0045,  ...,  0.0237, -0.0032,  0.0158],\n",
      "        [ 0.0217,  0.0036, -0.0299,  ..., -0.0260,  0.0161, -0.0278],\n",
      "        [ 0.0023, -0.0103,  0.0283,  ..., -0.0139,  0.0264,  0.0341]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n",
      "        [ 0.0032,  0.0032,  0.0032,  ...,  0.0032,  0.0032,  0.0032]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "#Clear the gradients , do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weight -  Parameter containing:\n",
      "tensor([[ 0.0150,  0.0338,  0.0030,  ..., -0.0187,  0.0102,  0.0152],\n",
      "        [ 0.0268, -0.0235, -0.0029,  ..., -0.0066,  0.0177, -0.0256],\n",
      "        [-0.0166, -0.0094,  0.0173,  ...,  0.0129, -0.0040, -0.0309],\n",
      "        ...,\n",
      "        [-0.0335, -0.0029, -0.0045,  ...,  0.0237, -0.0032,  0.0158],\n",
      "        [ 0.0217,  0.0036, -0.0299,  ..., -0.0260,  0.0161, -0.0278],\n",
      "        [ 0.0023, -0.0104,  0.0283,  ..., -0.0139,  0.0263,  0.0341]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weight - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.915807747256273\n",
      "Training loss: 0.8364984420443903\n",
      "Training loss: 0.5194293756856084\n",
      "Training loss: 0.43283832173294096\n",
      "Training loss: 0.3901805018724155\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        # Clear the gradients, do this because gradients are accumulated\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass, then backward pass, then update weights\n",
    "        output= model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        # Take an update step and few the new weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels= next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1,784)\n",
    "#turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "#output of the network are log-probabilities , need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
